{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7049e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "g = Digraph('G', node_attr={'style': 'filled'})\n",
    "\n",
    "with g.subgraph(name='cluster_cleaning') as c:\n",
    "    c.attr(color='black', label='Cleaning')\n",
    "    c.edges([\n",
    "        ('LangDetect', 'Lowercase'),\n",
    "        ('Lowercase', 'RemovePunctuation'),\n",
    "        ('RemovePunctuation', 'RemoveNonsenseSummary'),\n",
    "        ('RemoveNonsenseSummary', 'FilterEmptySummary')\n",
    "    ])\n",
    "    \n",
    "with g.subgraph(name='cluster_preprocess') as c:\n",
    "    c.attr(color='black', label='Preprocessing')\n",
    "    c.edges([\n",
    "        ('RemoveStopwords', 'Lemmatize'),\n",
    "        ('Lemmatize', 'Vectorize')\n",
    "    ])\n",
    "    \n",
    "with g.subgraph(name='cluster_dimred') as c:\n",
    "    c.attr(color='black', label='Dim. Reduction')\n",
    "    c.edges([\n",
    "        ('Scaler', 'ToDense'),\n",
    "        ('ToDense', 'PCA')\n",
    "    ])\n",
    "    \n",
    "with g.subgraph(name='cluster_title') as c:\n",
    "    c.attr(color='black', label='Title Features')\n",
    "    c.edges([\n",
    "        ('FilterEmptySummary', 'TitleCharCount'),\n",
    "        ('FilterEmptySummary', 'TitleWordCount'),\n",
    "        ('FilterEmptySummary', 'TitleStopwordCount'),\n",
    "        ('TitleCharCount', 'TitleAvgWordLen'),\n",
    "        ('TitleWordCount', 'TitleAvgWordLen')\n",
    "    ])\n",
    "\n",
    "with g.subgraph(name='cluster_summ') as c:\n",
    "    c.attr(color='black', label='Summary Features')\n",
    "    c.edges([\n",
    "        ('FilterEmptySummary', 'SummCharCount'),\n",
    "        ('FilterEmptySummary', 'SummWordCount'),\n",
    "        ('FilterEmptySummary', 'SummSentCount'),\n",
    "        ('FilterEmptySummary', 'SummStopwordCount'),\n",
    "        ('SummCharCount', 'SummAvgWordLen'),\n",
    "        ('SummWordCount', 'SummAvgWordLen'),\n",
    "        ('SummWordCount', 'SummAvgSentLen'),\n",
    "        ('SummSentCount', 'SummAvgSentLen'),\n",
    "    ])\n",
    "    \n",
    "with g.subgraph(name='cluster_combined') as c:\n",
    "    c.attr(color='black', label='Combined Text Features')\n",
    "    c.edges([\n",
    "        ('FilterEmptySummary', 'UniqueWordCount'),\n",
    "        ('FilterEmptySummary', 'SentimentScore')\n",
    "    ])\n",
    "\n",
    "g.edge('RawData', 'LangDetect')\n",
    "g.edge('FilterEmptySummary', 'RemoveStopwords')\n",
    "g.edge('Vectorize', 'Scaler')\n",
    "\n",
    "feature_list = [\n",
    "    'PCA', 'TitleCharCount', 'TitleWordCount', 'TitleStopwordCount', 'TitleAvgWordLen',\n",
    "    'SummCharCount', 'SummWordCount', 'SummSentCount', 'SummStopwordCount', 'SummAvgWordLen',\n",
    "    'SummAvgSentLen', 'UniqueWordCount', 'SentimentScore'\n",
    "]\n",
    "\n",
    "for f in feature_list:\n",
    "    g.edge(f, 'FeatureUnion')\n",
    "    \n",
    "with g.subgraph(name='clust_finaldimred') as c:\n",
    "    c.attr(color='black', label='Final Dim. Reduction')\n",
    "    c.edges([\n",
    "        ('FinalScaler', 'FinalToDense'),\n",
    "        ('FinalToDense', 'FinalPCA')\n",
    "    ])\n",
    "\n",
    "g.edge('FeatureUnion', 'FinalScaler')\n",
    "g.edge('FinalPCA', 'Model')\n",
    "\n",
    "u = g.unflatten(stagger=3)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c26588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4657, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset URL:\n",
    "# https://www.kaggle.com/datasets/athu1105/book-genre-prediction\n",
    "\n",
    "# Read the data into dataframe\n",
    "df = pd.read_csv('../data/book_genre_dataset.csv')\n",
    "\n",
    "# Create a column with the combined title and summary\n",
    "df['combined'] = df['title'] + '. ' + df['summary']\n",
    "\n",
    "X = df[['title', 'summary', 'combined']]\n",
    "y = df['genre']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df9ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.loc[:,self.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1cb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect\n",
    "\n",
    "class LangDetection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lang='en'):\n",
    "        self.lang = lang\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        X_['lang'] = X_.apply(lambda x: langdetect.detect(x))\n",
    "        X_lang_only = X[X_['lang'] == self.lang]\n",
    "        return X_lang_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a920b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowercaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_lower = X.apply(lambda x: x.lower())\n",
    "        return X_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32660bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class RemovePunctuation(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_no_punct = X.apply(lambda x: re.sub(r'[^\\w\\s]|_', '', x))\n",
    "        return X_no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cbf242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDataEntries(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ids):\n",
    "        self.ids = ids\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for i in self.ids:\n",
    "            X_ = X_.drop(i)\n",
    "        return X_     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22a44f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nonsense_summaries_idx = [338, 588, 834, 1574, 1772, 2410, 2485]\n",
    "\n",
    "clean_text_pipeline = Pipeline([\n",
    "    #('get_combined_text', FeatureSelector('combined')),\n",
    "    ('detect_lang', LangDetection()),\n",
    "    ('lowercase',    LowercaseTransformer()),\n",
    "    ('remove_punctuation', RemovePunctuation()),\n",
    "    ('drop_nonsense_summaries', DropDataEntries(nonsense_summaries_idx))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf061d1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclean_text_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:635\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    633\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[0;32m--> 635\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "Cell \u001b[0;32mIn [6], line 10\u001b[0m, in \u001b[0;36mLangDetection.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m      9\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 10\u001b[0m     X_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangdetect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     X_lang_only \u001b[38;5;241m=\u001b[39m X[X_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_lang_only\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [6], line 10\u001b[0m, in \u001b[0;36mLangDetection.transform.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m      9\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 10\u001b[0m     X_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X_\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mlangdetect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     X_lang_only \u001b[38;5;241m=\u001b[39m X[X_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_lang_only\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langdetect/detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langdetect/detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langdetect/detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langdetect/detector.py:163\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_lang_prob(prob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(ngrams), alpha)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONV_THRESHOLD \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mITERATION_LIMIT:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langdetect/detector.py:231\u001b[0m, in \u001b[0;36mDetector._normalize_prob\u001b[0;34m(self, prob)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m maxp \u001b[38;5;241m<\u001b[39m p:\n\u001b[1;32m    230\u001b[0m         maxp \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 231\u001b[0m     prob[i] \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maxp\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clean_text_pipeline.transform(X['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ff282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a70061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
