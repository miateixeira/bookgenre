{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a60ae1a",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca236c",
   "metadata": {},
   "source": [
    "Having taken a preliminary look at our data, we now work toward building a pipeline, comparing some models, and performing hyperparameter tuning on the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43a3e6",
   "metadata": {},
   "source": [
    "## Importing preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d046d",
   "metadata": {},
   "source": [
    "We read in the preprocessed data using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c26588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset URL:\n",
    "# https://www.kaggle.com/datasets/athu1105/book-genre-prediction\n",
    "\n",
    "# Read the data into dataframe\n",
    "df = pd.read_csv('../data/book_genre_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9843b657",
   "metadata": {},
   "source": [
    "We create a new column in our dataframe that is concatenation of the book title and summary. This combined text is what we will treat as our primary input text for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c56adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined'] = df['title'] + '. ' + df['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce216cd9",
   "metadata": {},
   "source": [
    "## Preprocess combined text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5666a8",
   "metadata": {},
   "source": [
    "Since the combined text has not been preprocessed, we recreate part of the preprocessing pipeline from the exploratory data analysis here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f8dbc",
   "metadata": {},
   "source": [
    "### Feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df9ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.loc[:,self.variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f6de9",
   "metadata": {},
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1cb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect\n",
    "\n",
    "class LangDetection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lang='en'):\n",
    "        self.lang = lang\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        X_['lang'] = X_.apply(lambda x: langdetect.detect(x))\n",
    "        X_lang_only = X[X_['lang'] == self.lang]\n",
    "        return X_lang_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac1ac4",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a920b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowercaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_lower = X.apply(lambda x: x.lower())\n",
    "        return X_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c82a96",
   "metadata": {},
   "source": [
    "### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32660bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class RemovePunctuation(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_no_punct = X.apply(lambda x: re.sub(r'[^\\w\\s]|_', '', x))\n",
    "        return X_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335206f",
   "metadata": {},
   "source": [
    "### Dropping data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cbf242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDataEntries(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ids):\n",
    "        self.ids = ids\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for i in self.ids:\n",
    "            X_ = X_.drop(i)\n",
    "        return X_     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2bc85e",
   "metadata": {},
   "source": [
    "## Clean text pipeline\n",
    "\n",
    "We create a pipeline out of these custom transformers in order to clean up the combined text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a44f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nonsense_summaries_idx = [338, 588, 834, 1574, 1772, 2410, 2485]\n",
    "\n",
    "clean_text_pipeline = Pipeline([\n",
    "    ('get_combined_text', FeatureSelector('combined')),\n",
    "    ('detect_lang', LangDetection()),\n",
    "    ('lowercase',    LowercaseTransformer()),\n",
    "    ('remove_punctuation', RemovePunctuation()),\n",
    "    ('drop_nonsense_summaries', DropDataEntries(nonsense_summaries_idx))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68ff282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;get_combined_text&#x27;, FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                (&#x27;detect_lang&#x27;, LangDetection()),\n",
       "                (&#x27;lowercase&#x27;, LowercaseTransformer()),\n",
       "                (&#x27;remove_punctuation&#x27;, RemovePunctuation()),\n",
       "                (&#x27;drop_nonsense_summaries&#x27;,\n",
       "                 DropDataEntries(ids=[338, 588, 834, 1574, 1772, 2410, 2485]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;get_combined_text&#x27;, FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                (&#x27;detect_lang&#x27;, LangDetection()),\n",
       "                (&#x27;lowercase&#x27;, LowercaseTransformer()),\n",
       "                (&#x27;remove_punctuation&#x27;, RemovePunctuation()),\n",
       "                (&#x27;drop_nonsense_summaries&#x27;,\n",
       "                 DropDataEntries(ids=[338, 588, 834, 1574, 1772, 2410, 2485]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(variables=&#x27;combined&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LangDetection</label><div class=\"sk-toggleable__content\"><pre>LangDetection()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LowercaseTransformer</label><div class=\"sk-toggleable__content\"><pre>LowercaseTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePunctuation</label><div class=\"sk-toggleable__content\"><pre>RemovePunctuation()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DropDataEntries</label><div class=\"sk-toggleable__content\"><pre>DropDataEntries(ids=[338, 588, 834, 1574, 1772, 2410, 2485])</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('get_combined_text', FeatureSelector(variables='combined')),\n",
       "                ('detect_lang', LangDetection()),\n",
       "                ('lowercase', LowercaseTransformer()),\n",
       "                ('remove_punctuation', RemovePunctuation()),\n",
       "                ('drop_nonsense_summaries',\n",
       "                 DropDataEntries(ids=[338, 588, 834, 1574, 1772, 2410, 2485]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f0424",
   "metadata": {},
   "source": [
    "We now use the `fit_transform()` method to apply the cleaning to the combined text column of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf061d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_clean = clean_text_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58badd3",
   "metadata": {},
   "source": [
    "We drop all of the rows which resulted in an empty string due to the cleaning of the combined text, and we create our new input data for the model, consisting of the title, summary, and combined text. This comes to a total of 4,657 entries in our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db8a9f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4657, 3), (4657,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([i for i in range(len(df)) if i not in X_combined_clean])\n",
    "X = df[['title','summary','combined']]\n",
    "y = df['genre']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cecb96",
   "metadata": {},
   "source": [
    "## Further preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74462c3",
   "metadata": {},
   "source": [
    "To finish the second part of our preprocessing, we once again reuse part of the preprocessing from the exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a3630",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "465a342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class RemoveStopwords(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stopwords):\n",
    "        self.stopwords = stopwords\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_no_stopwords = X.apply(lambda x: ' '.join([w for w in x.split() if w not in self.stopwords]))\n",
    "        return X_no_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637e100",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76a71311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class Lemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lemmatizer):\n",
    "        self.lemmatizer = lemmatizer\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        lemmatize_func = lambda x: ' '.join(\n",
    "            [self.lemmatizer.lemmatize(w) for w in x.split()]\n",
    "        )\n",
    "        X_lemmatized = X.apply(lemmatize_func)\n",
    "        return X_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000fd50",
   "metadata": {},
   "source": [
    "### Removing short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09866805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveShortWords(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda x: ' '.join([x for x in x.split() if len(x) > 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a298c1d",
   "metadata": {},
   "source": [
    "## Putting preprocessing pipeline together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c15b8",
   "metadata": {},
   "source": [
    "We create a preprocessing pipeline containing the `RemoveStopwords`, `Lemmatizer`, and `RemoveShortWords` transformers defined above. In addition, we include a `TfidfVectorizer` and `SelectKBest`.\n",
    "\n",
    "In order to convert the raw text in our data into a format that our models can use as input, we need to vectorize the text. This means converting the text into numerical vectors.\n",
    "\n",
    "The method we'll use for this is TF-IDF (term frequency-inverse document frequency). For a given term (i.e. word), the TF-IDF score is proportional to the frequency of the word in the given document (i.e. a particular summary), and inversely proportional to the frequency of documents containing that term. In other words, the more frequent a word is in a given summary the more important it is, and if the word appears in many different summaries it's less important.\n",
    "\n",
    "Since the TF-IDF vectorizer creates a very large matrix (the number of features will equal the size of the vocabulary, i.e. all the unique words across all the input text), we use the `SelectKBest` transformer provided by `sklearn`. The `SelectKBest` transformer works by calculating ANOVA F-values between labels and features, and selecting the `k` features that are most predictive of the correct labels. This provides a way to pare down the size of our vectorized input data. For now, we select the 5,000 most predictive features. Later, we'll tune our model with `k` as a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8a70061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "\n",
    "preprocess_text_pipeline = Pipeline([\n",
    "    ('remove_stopwords', RemoveStopwords(stop_words)),\n",
    "    ('lemmatize', Lemmatizer(WordNetLemmatizer())),\n",
    "    ('remove_short_words', RemoveShortWords()),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('select_k_best', SelectKBest(k=5000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc23be4",
   "metadata": {},
   "source": [
    "To finalize our main text pipeline, we use the `FeatureSelector` to extract the `combined` column of our dataset, and apply the `preprocess_text_pipeline` to the combined column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac280fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = Pipeline([\n",
    "    ('select_combined', FeatureSelector('combined')),\n",
    "    ('preprocess', preprocess_text_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b9647",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea409b77",
   "metadata": {},
   "source": [
    "In order to augment our input data, we'll define some hand-crafted features that contain potentially predictive information explicitly.\n",
    "\n",
    "To this end, we define a new custom transformer that creates new data columns containing each of the following features for both the title and the summary:\n",
    "\n",
    "- **char_count:** number of characters in the title/summary\n",
    "- **word_count:** number of words in the title/summary\n",
    "- **avg_word_len:** average number of characters per word in the title/summary\n",
    "- **stopword_count:** the number of stopwords in the title/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2a3f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_count(text):\n",
    "    stopwords_in_text = [w for w in text.split() if w in stop_words]\n",
    "    return len(stopwords_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8953b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleSummaryFE(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        feats = pd.DataFrame()\n",
    "        feats['char_count'] = X_.apply(lambda x: len(x))\n",
    "        feats['word_count'] = X_.apply(lambda x: len(x.split()))\n",
    "        feats['avg_word_len'] = feats['char_count'] / feats['word_count']\n",
    "        feats['stopword_count'] = X_.apply(stopword_count)\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194ddab",
   "metadata": {},
   "source": [
    "Like we did for preprocessing the combined text, we create two new pipelines that extract the title and summary, respectively, and create the new features for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09da0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_features = Pipeline([\n",
    "    ('select_title', FeatureSelector('title')),\n",
    "    ('title_features', TitleSummaryFE()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1a3ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_features = Pipeline([\n",
    "    ('select_summary', FeatureSelector('summary')),\n",
    "    ('summary_features', TitleSummaryFE()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552edb6f",
   "metadata": {},
   "source": [
    "Finally, we create a transformer for creating the features from the combined text.\n",
    "\n",
    "- **unique_word_count:** the total number of unique words in the combined text\n",
    "- **unique_word_ratio:** the proportion of words in the combined text that are unique\n",
    "- **sentiment_score:** the compound sentiment anaysis score as calculated by the `Sentiment Intensity Analyzer` provided by `nltk.sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d8c706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "class CombinedFE(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        feats = pd.DataFrame()\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        X_ = X.copy()\n",
    "        feats['unique_word_count'] = X_.apply(lambda x: len(set(x.split())))\n",
    "        feats['unique_word_ratio'] = feats['unique_word_count'] / X_.apply(lambda x: len(x.split()))\n",
    "        feats['sentiment_score'] = X_.apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b71990",
   "metadata": {},
   "source": [
    "As before, we create a new pipeline that extracts the combined text column of the data, and generates the relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f4ea9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = Pipeline([\n",
    "    ('select_combined', FeatureSelector('combined')),\n",
    "    ('combined_features', CombinedFE()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517622b8",
   "metadata": {},
   "source": [
    "## Putting it all together and comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abe8ab",
   "metadata": {},
   "source": [
    "In order to finalize our input data for the model, use the `FeatureUnion` provided by `sklearn`. The `FeatureUnion` works the same as a `Pipeline`, but the transformers are applied in parallel rather than in series.\n",
    "\n",
    "We therefore define `features`, which will apply the `text_pipeline`, `title_features`, `summary_features`, and `combined_features` transformers in parallel. The output of this transformer will be a dataframe that contains the processed and vectorized combined text, as well as all of the hand-crafted title, summary, and combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8d01725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "features = FeatureUnion([\n",
    "    ('text', text_pipeline),\n",
    "    ('title', title_features),\n",
    "    ('summary', summary_features),\n",
    "    ('combined', combined_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d49c34",
   "metadata": {},
   "source": [
    "In order to be able to run multiple experiments with our models, we define `run_experiment()`, which takes the following input:\n",
    "- **X:** input dataframe\n",
    "- **y:** gold labels\n",
    "- **pipeline:** an scikit-learn `Pipeline` object that implements a model we wish to train and evaluate\n",
    "- **num_expts:** (default is 5) the number of experiments to run\n",
    "\n",
    "We start by using `train_test_split` to set aside 20% of the data for evaluation, using the remaining 80% to train our model. We then fit the model on our training data, predict labels using the trained model, and calculate the accuracy score of our model. This is done `num_expts` many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93611f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def run_experiment(X, y, pipeline, num_expts=5):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "        model = pipeline.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print(f\"Average accuracy over {num_expts} experiments: {sum(scores) / num_expts} \\n\")\n",
    "    print(\"Classification report for the last experiment:\\n\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fac564",
   "metadata": {},
   "source": [
    "Since we want to compare multiple models, we define a helper function `model_pipeline()` which takes a model object (e.g. `LinearSVC()`) and creates a pipeline that combines the the feature generation with the input model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3cc0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(model):\n",
    "    pipeline = Pipeline([\n",
    "        ('features', features),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b275a7",
   "metadata": {},
   "source": [
    "For this project, we decide to compare a Linear Support Vector Classification (`LinearSVC`), a k-nearest neighbors classifier (`KNeighborsClassifier`), and a decision tree classifier (`DecisionTreeClassifier`).\n",
    "\n",
    "We then run five experiments with each of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bbfac3",
   "metadata": {},
   "source": [
    "### Linear Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adb0cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 5 experiments: 0.6622317596566523 \n",
      "\n",
      "Classification report for the last experiment:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.74      0.70      0.72        99\n",
      "     fantasy       0.65      0.78      0.71       183\n",
      "     history       0.66      0.70      0.68       127\n",
      "      horror       0.61      0.55      0.58       121\n",
      "  psychology       0.94      0.62      0.75        24\n",
      "     romance       0.50      0.36      0.42        14\n",
      "     science       0.68      0.65      0.66       130\n",
      "      sports       0.64      0.64      0.64        14\n",
      "    thriller       0.61      0.61      0.61       203\n",
      "      travel       0.69      0.53      0.60        17\n",
      "\n",
      "    accuracy                           0.66       932\n",
      "   macro avg       0.67      0.61      0.64       932\n",
      "weighted avg       0.66      0.66      0.65       932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(dual=False)\n",
    "run_experiment(X, y, model_pipeline(svc), num_expts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336d759",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92bfc7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 5 experiments: 0.21716738197424892 \n",
      "\n",
      "Classification report for the last experiment:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.13      0.22      0.17        94\n",
      "     fantasy       0.25      0.42      0.31       163\n",
      "     history       0.20      0.17      0.18       121\n",
      "      horror       0.20      0.13      0.16       126\n",
      "  psychology       0.22      0.19      0.21        21\n",
      "     romance       0.00      0.00      0.00        16\n",
      "     science       0.23      0.13      0.17       139\n",
      "      sports       0.29      0.06      0.11        31\n",
      "    thriller       0.32      0.32      0.32       199\n",
      "      travel       0.17      0.05      0.07        22\n",
      "\n",
      "    accuracy                           0.23       932\n",
      "   macro avg       0.20      0.17      0.17       932\n",
      "weighted avg       0.23      0.23      0.22       932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "run_experiment(X, y, model_pipeline(knn), num_expts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fbd3b",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b050e0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 5 experiments: 0.453862660944206 \n",
      "\n",
      "Classification report for the last experiment:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.55      0.49      0.52       117\n",
      "     fantasy       0.48      0.51      0.49       166\n",
      "     history       0.45      0.48      0.47       115\n",
      "      horror       0.32      0.30      0.31       117\n",
      "  psychology       0.31      0.29      0.30        14\n",
      "     romance       0.23      0.24      0.23        21\n",
      "     science       0.39      0.42      0.40       129\n",
      "      sports       0.70      0.58      0.64        24\n",
      "    thriller       0.51      0.51      0.51       211\n",
      "      travel       0.42      0.28      0.33        18\n",
      "\n",
      "    accuracy                           0.45       932\n",
      "   macro avg       0.43      0.41      0.42       932\n",
      "weighted avg       0.45      0.45      0.45       932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "run_experiment(X, y, model_pipeline(dtree), num_expts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301b38d",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2372f",
   "metadata": {},
   "source": [
    "As we can see from our model comparison above, the `LinearSVC` was the best-performing model by quite a wide margin across five experiments compared to the `KNeighborsClassifier` and the `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db98d40",
   "metadata": {},
   "source": [
    "In order to perform hyperparameter tuning on the `LinearSVC` model, we first define a dict with all the parameters we want to consider in our search grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92963c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # tf-idf params\n",
    "    \"features__text__preprocess__tfidf__max_df\" : [0.6, 0.8, 1.0],\n",
    "    \"features__text__preprocess__tfidf__min_df\" : [1, 3, 5],\n",
    "    \"features__text__preprocess__tfidf__ngram_range\" : [(1, 1), (1, 2)],\n",
    "    \"features__text__preprocess__tfidf__norm\" : [\"l1\", \"l2\"],    \n",
    "    # select k-best params\n",
    "    \"features__text__preprocess__select_k_best__k\" : [100,1000,5000],\n",
    "    # svc model params\n",
    "    \"model__C\" : [0.1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32487b",
   "metadata": {},
   "source": [
    "We then define a `GridSearchCV` object with the `LinearSVC` estimator object and the dict of parameters from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eea61a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = LinearSVC(dual=False)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = model_pipeline(svc),\n",
    "    param_grid = params,\n",
    "    cv = 3,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f7545",
   "metadata": {},
   "source": [
    "Before performing the grid search, we do a train-test split of the data. While the grid search itself performs a train-test split for cross-validation, we reserve 10% of the data from the grid search in order to preempt any information \"leaks\" in the algorithm. We can then use this withheld 10% of the data to get more representative accuracy that we may expect of the optimized model from unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "699b91ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29b921",
   "metadata": {},
   "source": [
    "Run the grid search.\n",
    "\n",
    "**NOTE:** this takes very long to run!! Depending on your computer, the number of parameter combinations, and the number of cross-validation folds, this will vary. As is here, it will take approximately 4 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4801ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;text&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;select_combined&#x27;,\n",
       "                                                                                         FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                                                                                        (&#x27;preprocess&#x27;,\n",
       "                                                                                         Pipeline(steps=[(&#x27;remove_stopwords&#x27;,\n",
       "                                                                                                          RemoveStopwords(stopwords={&#x27;a&#x27;,\n",
       "                                                                                                                                     &#x27;about&#x27;,\n",
       "                                                                                                                                     &#x27;above&#x27;,\n",
       "                                                                                                                                     &#x27;after&#x27;,\n",
       "                                                                                                                                     &#x27;again&#x27;,\n",
       "                                                                                                                                     &#x27;against&#x27;,\n",
       "                                                                                                                                     &#x27;ain&#x27;,\n",
       "                                                                                                                                     &#x27;all&#x27;,\n",
       "                                                                                                                                     &#x27;am&#x27;,\n",
       "                                                                                                                                     &#x27;an&#x27;,\n",
       "                                                                                                                                     &#x27;and&#x27;,\n",
       "                                                                                                                                     &#x27;any&#x27;,\n",
       "                                                                                                                                     &#x27;are&#x27;,\n",
       "                                                                                                                                     &#x27;aren&#x27;,\n",
       "                                                                                                                                     &quot;aren&#x27;t&quot;,\n",
       "                                                                                                                                     &#x27;a...\n",
       "                                       (&#x27;model&#x27;, LinearSVC(dual=False))]),\n",
       "             param_grid={&#x27;features__text__preprocess__select_k_best__k&#x27;: [100,\n",
       "                                                                          1000,\n",
       "                                                                          5000],\n",
       "                         &#x27;features__text__preprocess__tfidf__max_df&#x27;: [0.6, 0.8,\n",
       "                                                                       1.0],\n",
       "                         &#x27;features__text__preprocess__tfidf__min_df&#x27;: [1, 3, 5],\n",
       "                         &#x27;features__text__preprocess__tfidf__ngram_range&#x27;: [(1,\n",
       "                                                                             1),\n",
       "                                                                            (1,\n",
       "                                                                             2)],\n",
       "                         &#x27;features__text__preprocess__tfidf__norm&#x27;: [&#x27;l1&#x27;,\n",
       "                                                                     &#x27;l2&#x27;],\n",
       "                         &#x27;model__C&#x27;: [0.1, 1]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;text&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;select_combined&#x27;,\n",
       "                                                                                         FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                                                                                        (&#x27;preprocess&#x27;,\n",
       "                                                                                         Pipeline(steps=[(&#x27;remove_stopwords&#x27;,\n",
       "                                                                                                          RemoveStopwords(stopwords={&#x27;a&#x27;,\n",
       "                                                                                                                                     &#x27;about&#x27;,\n",
       "                                                                                                                                     &#x27;above&#x27;,\n",
       "                                                                                                                                     &#x27;after&#x27;,\n",
       "                                                                                                                                     &#x27;again&#x27;,\n",
       "                                                                                                                                     &#x27;against&#x27;,\n",
       "                                                                                                                                     &#x27;ain&#x27;,\n",
       "                                                                                                                                     &#x27;all&#x27;,\n",
       "                                                                                                                                     &#x27;am&#x27;,\n",
       "                                                                                                                                     &#x27;an&#x27;,\n",
       "                                                                                                                                     &#x27;and&#x27;,\n",
       "                                                                                                                                     &#x27;any&#x27;,\n",
       "                                                                                                                                     &#x27;are&#x27;,\n",
       "                                                                                                                                     &#x27;aren&#x27;,\n",
       "                                                                                                                                     &quot;aren&#x27;t&quot;,\n",
       "                                                                                                                                     &#x27;a...\n",
       "                                       (&#x27;model&#x27;, LinearSVC(dual=False))]),\n",
       "             param_grid={&#x27;features__text__preprocess__select_k_best__k&#x27;: [100,\n",
       "                                                                          1000,\n",
       "                                                                          5000],\n",
       "                         &#x27;features__text__preprocess__tfidf__max_df&#x27;: [0.6, 0.8,\n",
       "                                                                       1.0],\n",
       "                         &#x27;features__text__preprocess__tfidf__min_df&#x27;: [1, 3, 5],\n",
       "                         &#x27;features__text__preprocess__tfidf__ngram_range&#x27;: [(1,\n",
       "                                                                             1),\n",
       "                                                                            (1,\n",
       "                                                                             2)],\n",
       "                         &#x27;features__text__preprocess__tfidf__norm&#x27;: [&#x27;l1&#x27;,\n",
       "                                                                     &#x27;l2&#x27;],\n",
       "                         &#x27;model__C&#x27;: [0.1, 1]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;text&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;select_combined&#x27;,\n",
       "                                                                  FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                                                                 (&#x27;preprocess&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;remove_stopwords&#x27;,\n",
       "                                                                                   RemoveStopwords(stopwords={&#x27;a&#x27;,\n",
       "                                                                                                              &#x27;about&#x27;,\n",
       "                                                                                                              &#x27;above&#x27;,\n",
       "                                                                                                              &#x27;after&#x27;,\n",
       "                                                                                                              &#x27;again&#x27;,\n",
       "                                                                                                              &#x27;against&#x27;,\n",
       "                                                                                                              &#x27;ain&#x27;,\n",
       "                                                                                                              &#x27;all&#x27;,\n",
       "                                                                                                              &#x27;am&#x27;,\n",
       "                                                                                                              &#x27;an&#x27;,\n",
       "                                                                                                              &#x27;and&#x27;,\n",
       "                                                                                                              &#x27;any&#x27;,\n",
       "                                                                                                              &#x27;are&#x27;,\n",
       "                                                                                                              &#x27;aren&#x27;,\n",
       "                                                                                                              &quot;aren&#x27;t&quot;,\n",
       "                                                                                                              &#x27;as&#x27;,\n",
       "                                                                                                              &#x27;at&#x27;,\n",
       "                                                                                                              &#x27;be&#x27;,\n",
       "                                                                                                              &#x27;because&#x27;,\n",
       "                                                                                                              &#x27;been...\n",
       "                                                                  FeatureSelector(variables=&#x27;title&#x27;)),\n",
       "                                                                 (&#x27;title_features&#x27;,\n",
       "                                                                  TitleSummaryFE())])),\n",
       "                                                (&#x27;summary&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;select_summary&#x27;,\n",
       "                                                                  FeatureSelector(variables=&#x27;summary&#x27;)),\n",
       "                                                                 (&#x27;summary_features&#x27;,\n",
       "                                                                  TitleSummaryFE())])),\n",
       "                                                (&#x27;combined&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;select_combined&#x27;,\n",
       "                                                                  FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                                                                 (&#x27;combined_features&#x27;,\n",
       "                                                                  CombinedFE())]))])),\n",
       "                (&#x27;model&#x27;, LinearSVC(dual=False))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;text&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;select_combined&#x27;,\n",
       "                                                 FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                                                (&#x27;preprocess&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;remove_stopwords&#x27;,\n",
       "                                                                  RemoveStopwords(stopwords={&#x27;a&#x27;,\n",
       "                                                                                             &#x27;about&#x27;,\n",
       "                                                                                             &#x27;above&#x27;,\n",
       "                                                                                             &#x27;after&#x27;,\n",
       "                                                                                             &#x27;again&#x27;,\n",
       "                                                                                             &#x27;against&#x27;,\n",
       "                                                                                             &#x27;ain&#x27;,\n",
       "                                                                                             &#x27;all&#x27;,\n",
       "                                                                                             &#x27;am&#x27;,\n",
       "                                                                                             &#x27;an&#x27;,\n",
       "                                                                                             &#x27;and&#x27;,\n",
       "                                                                                             &#x27;any&#x27;,\n",
       "                                                                                             &#x27;are&#x27;,\n",
       "                                                                                             &#x27;aren&#x27;,\n",
       "                                                                                             &quot;aren&#x27;t&quot;,\n",
       "                                                                                             &#x27;as&#x27;,\n",
       "                                                                                             &#x27;at&#x27;,\n",
       "                                                                                             &#x27;be&#x27;,\n",
       "                                                                                             &#x27;because&#x27;,\n",
       "                                                                                             &#x27;been&#x27;,\n",
       "                                                                                             &#x27;before&#x27;,\n",
       "                                                                                             &#x27;being&#x27;,\n",
       "                                                                                             &#x27;below&#x27;,\n",
       "                                                                                             &#x27;...\n",
       "                                Pipeline(steps=[(&#x27;select_title&#x27;,\n",
       "                                                 FeatureSelector(variables=&#x27;title&#x27;)),\n",
       "                                                (&#x27;title_features&#x27;,\n",
       "                                                 TitleSummaryFE())])),\n",
       "                               (&#x27;summary&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;select_summary&#x27;,\n",
       "                                                 FeatureSelector(variables=&#x27;summary&#x27;)),\n",
       "                                                (&#x27;summary_features&#x27;,\n",
       "                                                 TitleSummaryFE())])),\n",
       "                               (&#x27;combined&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;select_combined&#x27;,\n",
       "                                                 FeatureSelector(variables=&#x27;combined&#x27;)),\n",
       "                                                (&#x27;combined_features&#x27;,\n",
       "                                                 CombinedFE())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>text</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(variables=&#x27;combined&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;remove_stopwords&#x27;,\n",
       "                 RemoveStopwords(stopwords={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                            &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                            &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                            &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                            &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;, &#x27;both&#x27;,\n",
       "                                            &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;,\n",
       "                                            &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;lemmatize&#x27;, Lemmatizer(lemmatizer=&lt;WordNetLemmatizer&gt;)),\n",
       "                (&#x27;remove_short_words&#x27;, RemoveShortWords()),\n",
       "                (&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;select_k_best&#x27;, SelectKBest(k=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveStopwords</label><div class=\"sk-toggleable__content\"><pre>RemoveStopwords(stopwords={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                           &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                           &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                           &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                           &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lemmatizer</label><div class=\"sk-toggleable__content\"><pre>Lemmatizer(lemmatizer=&lt;WordNetLemmatizer&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveShortWords</label><div class=\"sk-toggleable__content\"><pre>RemoveShortWords()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=5000)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>title</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(variables=&#x27;title&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TitleSummaryFE</label><div class=\"sk-toggleable__content\"><pre>TitleSummaryFE()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>summary</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(variables=&#x27;summary&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TitleSummaryFE</label><div class=\"sk-toggleable__content\"><pre>TitleSummaryFE()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>combined</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(variables=&#x27;combined&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CombinedFE</label><div class=\"sk-toggleable__content\"><pre>CombinedFE()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(dual=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text',\n",
       "                                                                        Pipeline(steps=[('select_combined',\n",
       "                                                                                         FeatureSelector(variables='combined')),\n",
       "                                                                                        ('preprocess',\n",
       "                                                                                         Pipeline(steps=[('remove_stopwords',\n",
       "                                                                                                          RemoveStopwords(stopwords={'a',\n",
       "                                                                                                                                     'about',\n",
       "                                                                                                                                     'above',\n",
       "                                                                                                                                     'after',\n",
       "                                                                                                                                     'again',\n",
       "                                                                                                                                     'against',\n",
       "                                                                                                                                     'ain',\n",
       "                                                                                                                                     'all',\n",
       "                                                                                                                                     'am',\n",
       "                                                                                                                                     'an',\n",
       "                                                                                                                                     'and',\n",
       "                                                                                                                                     'any',\n",
       "                                                                                                                                     'are',\n",
       "                                                                                                                                     'aren',\n",
       "                                                                                                                                     \"aren't\",\n",
       "                                                                                                                                     'a...\n",
       "                                       ('model', LinearSVC(dual=False))]),\n",
       "             param_grid={'features__text__preprocess__select_k_best__k': [100,\n",
       "                                                                          1000,\n",
       "                                                                          5000],\n",
       "                         'features__text__preprocess__tfidf__max_df': [0.6, 0.8,\n",
       "                                                                       1.0],\n",
       "                         'features__text__preprocess__tfidf__min_df': [1, 3, 5],\n",
       "                         'features__text__preprocess__tfidf__ngram_range': [(1,\n",
       "                                                                             1),\n",
       "                                                                            (1,\n",
       "                                                                             2)],\n",
       "                         'features__text__preprocess__tfidf__norm': ['l1',\n",
       "                                                                     'l2'],\n",
       "                         'model__C': [0.1, 1]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113abf3a",
   "metadata": {},
   "source": [
    "After running the grid search, we can get the best-performing combination of parameters from the `grid` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64a392a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features__text__preprocess__select_k_best__k': 5000,\n",
       " 'features__text__preprocess__tfidf__max_df': 0.6,\n",
       " 'features__text__preprocess__tfidf__min_df': 3,\n",
       " 'features__text__preprocess__tfidf__ngram_range': (1, 1),\n",
       " 'features__text__preprocess__tfidf__norm': 'l2',\n",
       " 'model__C': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c5095",
   "metadata": {},
   "source": [
    "And finally, we use the 10% of the data that we set aside before performing the grid search to evaluate the accuracy of the optimized model. This hyperparameter tuning resulted in an increase of about 2.5% in our accuracy, which is not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44b261da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6888412017167382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.61      0.57      0.59        53\n",
      "     fantasy       0.74      0.75      0.74        93\n",
      "     history       0.61      0.81      0.70        57\n",
      "      horror       0.73      0.60      0.66        50\n",
      "  psychology       1.00      0.50      0.67         8\n",
      "     romance       0.33      0.33      0.33         9\n",
      "     science       0.77      0.75      0.76        67\n",
      "      sports       0.78      0.70      0.74        10\n",
      "    thriller       0.65      0.69      0.67       102\n",
      "      travel       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.69       466\n",
      "   macro avg       0.72      0.63      0.66       466\n",
      "weighted avg       0.70      0.69      0.69       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = grid.predict(X_test)\n",
    "accuracy = accuracy_score(y_true, y_predicted)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_true, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
