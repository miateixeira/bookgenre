{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3d8cc4",
   "metadata": {},
   "source": [
    "# Reimplementing our model with Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd862c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/book_genre_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f383c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4640, 3) (4640,)\n"
     ]
    }
   ],
   "source": [
    "X = df[['combined_clean','title','summary']]\n",
    "#X = df['combined_clean']\n",
    "y = df['genre']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9811a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.asarray(X[self.column_name]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c898c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def chi2_tfidf(X, y, p_value_limit=0.95):\n",
    "    # initialize vectorizer with 10,000 features\n",
    "    tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "    X_tfidf = tfidf.fit_transform(X)\n",
    "    # extract vocabulary\n",
    "    dic_vocabulary = tfidf.vocabulary_\n",
    "    \n",
    "    # perform chi-square to determine whether a feature\n",
    "    # and the binary target (e.g. Fantasy or NotFantasy)\n",
    "    # are independent\n",
    "    X_names = tfidf.get_feature_names_out()\n",
    "    df_features = pd.DataFrame()\n",
    "    for label in np.unique(y):\n",
    "        chi_sq, p = chi2(X_tfidf, y==label)\n",
    "        df_features = pd.concat([df_features,\n",
    "                                 pd.DataFrame({\n",
    "                                     \"feature\": X_names,\n",
    "                                     \"score\": 1-p,\n",
    "                                     \"y\": label\n",
    "                                 })])\n",
    "        df_features = df_features.sort_values(['y','score'],ascending=[True,False])\n",
    "        # keep those with high-enough p-value\n",
    "        df_features = df_features[df_features[\"score\"]>p_value_limit]\n",
    "    return df_features['feature'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0eb4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "76fba5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Get the TF-IDF features that are most statistically \"relevant\"\n",
    "tfidf_vocab = chi2_tfidf(X_train['combined_clean'], y_train)\n",
    "# Initialize new TfidfVectorizer with the statistically \"relevant\" vocab\n",
    "tfidf = TfidfVectorizer(vocabulary=tfidf_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c26f6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('column_extractor', ColumnExtractor('combined_clean')),\n",
    "    ('tfidf', tfidf), # vectorize combined text\n",
    "    ('svc', svc),     # feed the output to classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "120e9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6508620689655172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.69      0.69      0.69        98\n",
      "     fantasy       0.72      0.71      0.72       181\n",
      "     history       0.64      0.71      0.67       121\n",
      "      horror       0.65      0.56      0.60       115\n",
      "  psychology       0.65      0.59      0.62        22\n",
      "     romance       0.45      0.18      0.26        28\n",
      "     science       0.68      0.64      0.66       131\n",
      "      sports       0.65      0.79      0.71        14\n",
      "    thriller       0.60      0.66      0.63       206\n",
      "      travel       0.41      0.75      0.53        12\n",
      "\n",
      "    accuracy                           0.65       928\n",
      "   macro avg       0.61      0.63      0.61       928\n",
      "weighted avg       0.65      0.65      0.65       928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = pipeline.fit(X_train, y_train) # train the classifier\n",
    "y_pred = model.predict(X_test)          # apply model to test set\n",
    "\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print (f\"Accuracy: {score}\")\n",
    "print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "25e76e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def run_experiment(X, y, pipeline, num_expts=100):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "        X_names = chi2_tfidf(X_train['combined_clean'], y_train)\n",
    "        pipeline = Pipeline([\n",
    "            ('column_extractor', ColumnExtractor('combined_clean')),\n",
    "            ('tfidf', TfidfVectorizer(vocabulary=X_names)), # vectorize combined text\n",
    "            ('svc', svc),     # feed the output to classifier\n",
    "        ])\n",
    "        model = pipeline.fit(X_train, y_train) # train the classifier\n",
    "        y_pred = model.predict(X_test)         # apply model to test set\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(f\"Average accuracy over {num_expts} experiments: {sum(scores) / num_expts}\\n\")\n",
    "    print(\"Classification report for the last experiment:\\n\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4a0787a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 5 experiments: 0.6549568965517242\n",
      "\n",
      "Classification report for the last experiment:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.72      0.66      0.69       101\n",
      "     fantasy       0.71      0.74      0.73       172\n",
      "     history       0.65      0.73      0.69       121\n",
      "      horror       0.60      0.54      0.57       114\n",
      "  psychology       0.80      0.55      0.65        22\n",
      "     romance       0.46      0.22      0.30        27\n",
      "     science       0.70      0.73      0.71       131\n",
      "      sports       0.83      0.80      0.82        25\n",
      "    thriller       0.61      0.66      0.63       196\n",
      "      travel       0.67      0.63      0.65        19\n",
      "\n",
      "    accuracy                           0.67       928\n",
      "   macro avg       0.68      0.63      0.64       928\n",
      "weighted avg       0.67      0.67      0.66       928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(X, y, pipeline, num_expts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70ebf9",
   "metadata": {},
   "source": [
    "# Adding features to our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "562b0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apply(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, fn):\n",
    "        self.fn = np.vectorize(fn)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        trans_data = self.fn(data.reshape(data.size, 1))\n",
    "        return trans_data\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "13108e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0c60bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def stopword_count(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]|_', '', text)\n",
    "    stopwords_in_text = [w for w in text.split() if w in stop_words]\n",
    "    return len(stopwords_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ed74b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Get the TF-IDF features that are most statistically \"relevant\"\n",
    "tfidf_vocab = chi2_tfidf(X_train['combined_clean'], y_train)\n",
    "# Initialize new TfidfVectorizer with the statistically \"relevant\" vocab\n",
    "tfidf = TfidfVectorizer(vocabulary=tfidf_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9cae0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('combined', Pipeline([\n",
    "            ('combined_extractor', ColumnExtractor('combined_clean')),\n",
    "            ('tfidf', tfidf),\n",
    "            ('scale', StandardScaler(with_mean=False)),\n",
    "            #('scale', RobustScaler(with_centering=False)),\n",
    "            ('to_dense', DenseTransformer()),\n",
    "            ('pca', PCA(n_components=5))\n",
    "            #('dim_reduction', TruncatedSVD())\n",
    "        ])),\n",
    "        ('title', Pipeline([\n",
    "            ('title_extractor', ColumnExtractor('title')), # extract titles\n",
    "            ('title_features', FeatureUnion([\n",
    "                ('title_char_count', Apply(lambda s: len(s))),\n",
    "        #        ('title_word_count', Apply(lambda s: len(s.split()))),\n",
    "        #        ('title_stopword_count', Apply(stopword_count))\n",
    "            ])),\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('to_dense', DenseTransformer()),\n",
    "    ('pca', PCA(n_components=4)),\n",
    "    ('svc', svc),     # feed the output to classifier\n",
    "    #('knn', knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1f253b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4870689655172414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.00      0.00      0.00       105\n",
      "     fantasy       0.54      0.71      0.61       181\n",
      "     history       0.59      0.48      0.53       127\n",
      "      horror       0.00      0.00      0.00       114\n",
      "  psychology       0.62      0.42      0.50        19\n",
      "     romance       0.00      0.00      0.00        18\n",
      "     science       0.61      0.73      0.66       136\n",
      "      sports       0.00      0.00      0.00        20\n",
      "    thriller       0.38      0.81      0.52       192\n",
      "      travel       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.49       928\n",
      "   macro avg       0.27      0.31      0.28       928\n",
      "weighted avg       0.37      0.49      0.41       928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mia/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/mia/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mia/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mia/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(X_train, y_train) # train the classifier\n",
    "y_pred = model.predict(X_test)          # apply model to test set\n",
    "\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print (f\"Accuracy: {score}\")\n",
    "print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf08a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755761c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
