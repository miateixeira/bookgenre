{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c82ffcd",
   "metadata": {},
   "source": [
    "# Model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2eba7c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"445pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 444.88 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 440.88,-472 440.88,4 -4,4\"/>\n",
       "<!-- Raw Data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Raw Data</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"221.29\" cy=\"-450\" rx=\"55.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.29\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Raw Data</text>\n",
       "</g>\n",
       "<!-- Preprocessing -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Preprocessing</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"221.29\" cy=\"-378\" rx=\"77.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.29\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Preprocessing</text>\n",
       "</g>\n",
       "<!-- Raw Data&#45;&gt;Preprocessing -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Raw Data&#45;&gt;Preprocessing</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.29,-431.7C221.29,-423.98 221.29,-414.71 221.29,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.79,-406.1 221.29,-396.1 217.79,-406.1 224.79,-406.1\"/>\n",
       "</g>\n",
       "<!-- Extract Combined Text -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Extract Combined Text</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118.29\" cy=\"-306\" rx=\"118.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.29\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Extract Combined Text</text>\n",
       "</g>\n",
       "<!-- Preprocessing&#45;&gt;Extract Combined Text -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Preprocessing&#45;&gt;Extract Combined Text</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.4,-360.76C183.69,-351.45 166.27,-339.61 151.27,-329.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153,-326.36 142.76,-323.63 149.07,-332.15 153,-326.36\"/>\n",
       "</g>\n",
       "<!-- Extract Title -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Extract Title</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"327.29\" cy=\"-306\" rx=\"69.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"327.29\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Extract Title</text>\n",
       "</g>\n",
       "<!-- Preprocessing&#45;&gt;Extract Title -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Preprocessing&#45;&gt;Extract Title</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M245.87,-360.76C260.43,-351.15 279.04,-338.87 294.79,-328.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"296.79,-331.34 303.2,-322.91 292.93,-325.5 296.79,-331.34\"/>\n",
       "</g>\n",
       "<!-- TF&#45;IDF Vectorizer -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>TF&#45;IDF Vectorizer</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"112.29\" cy=\"-234\" rx=\"92.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.29\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">TF&#45;IDF Vectorizer</text>\n",
       "</g>\n",
       "<!-- Extract Combined Text&#45;&gt;TF&#45;IDF Vectorizer -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Extract Combined Text&#45;&gt;TF&#45;IDF Vectorizer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116.81,-287.7C116.15,-279.98 115.35,-270.71 114.61,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.1,-261.77 113.76,-252.1 111.12,-262.37 118.1,-261.77\"/>\n",
       "</g>\n",
       "<!-- Feature Engineering -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Feature Engineering</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"330.29\" cy=\"-234\" rx=\"106.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"330.29\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Feature Engineering</text>\n",
       "</g>\n",
       "<!-- Extract Title&#45;&gt;Feature Engineering -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Extract Title&#45;&gt;Feature Engineering</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.03,-287.7C328.36,-279.98 328.76,-270.71 329.13,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.62,-262.25 329.56,-252.1 325.63,-261.95 332.62,-262.25\"/>\n",
       "</g>\n",
       "<!-- Scaling -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Scaling</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"221.29\" cy=\"-162\" rx=\"44.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.29\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Scaling</text>\n",
       "</g>\n",
       "<!-- TF&#45;IDF Vectorizer&#45;&gt;Scaling -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>TF&#45;IDF Vectorizer&#45;&gt;Scaling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137.85,-216.59C153.35,-206.63 173.25,-193.85 189.73,-183.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.96,-185.99 198.49,-177.64 188.18,-180.1 191.96,-185.99\"/>\n",
       "</g>\n",
       "<!-- Dimensionality Reduction -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Dimensionality Reduction</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"221.29\" cy=\"-90\" rx=\"129.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.29\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dimensionality Reduction</text>\n",
       "</g>\n",
       "<!-- Scaling&#45;&gt;Dimensionality Reduction -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Scaling&#45;&gt;Dimensionality Reduction</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215.41,-144.05C214.59,-136.35 214.35,-127.03 214.68,-118.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.18,-118.49 215.38,-108.28 211.2,-118.01 218.18,-118.49\"/>\n",
       "</g>\n",
       "<!-- Dimensionality Reduction&#45;&gt;Scaling -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Dimensionality Reduction&#45;&gt;Scaling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.2,-108.28C228,-116.03 228.23,-125.36 227.88,-134.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.38,-133.83 227.17,-144.05 231.37,-134.33 224.38,-133.83\"/>\n",
       "</g>\n",
       "<!-- Model Training -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Model Training</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"221.29\" cy=\"-18\" rx=\"81.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.29\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model Training</text>\n",
       "</g>\n",
       "<!-- Dimensionality Reduction&#45;&gt;Model Training -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>Dimensionality Reduction&#45;&gt;Model Training</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.29,-71.7C221.29,-63.98 221.29,-54.71 221.29,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.79,-46.1 221.29,-36.1 217.79,-46.1 224.79,-46.1\"/>\n",
       "</g>\n",
       "<!-- Feature Engineering&#45;&gt;Scaling -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Feature Engineering&#45;&gt;Scaling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M304.46,-216.41C288.95,-206.45 269.11,-193.71 252.69,-183.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.28,-180.03 243.98,-177.57 250.5,-185.92 254.28,-180.03\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f35cdba3940>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "g = Digraph('G')\n",
    "\n",
    "g.edge('Raw Data', 'Preprocessing')\n",
    "g.edge('Preprocessing', 'Extract Combined Text')\n",
    "g.edge('Preprocessing', 'Extract Title')\n",
    "g.edge('Extract Combined Text', 'TF-IDF Vectorizer')\n",
    "g.edge('TF-IDF Vectorizer', 'Scaling')\n",
    "g.edge('Scaling', 'Dimensionality Reduction')\n",
    "g.edge('Extract Title', 'Feature Engineering')\n",
    "g.edge('Feature Engineering', 'Scaling')\n",
    "g.edge('Dimensionality Reduction', 'Scaling')\n",
    "g.edge('Dimensionality Reduction', 'Model Training')\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ba245",
   "metadata": {},
   "source": [
    "# Reimplementing our model with Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06b9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/book_genre_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d97cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4640, 3) (4640,)\n"
     ]
    }
   ],
   "source": [
    "X = df[['combined_clean','title','summary']]\n",
    "#X = df['combined_clean']\n",
    "y = df['genre']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d78fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.asarray(X[self.column_name]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0dadb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def chi2_tfidf(X, y, p_value_limit=0.95):\n",
    "    # initialize vectorizer with 10,000 features\n",
    "    tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "    X_tfidf = tfidf.fit_transform(X)\n",
    "    # extract vocabulary\n",
    "    dic_vocabulary = tfidf.vocabulary_\n",
    "    \n",
    "    # perform chi-square to determine whether a feature\n",
    "    # and the binary target (e.g. Fantasy or NotFantasy)\n",
    "    # are independent\n",
    "    X_names = tfidf.get_feature_names_out()\n",
    "    df_features = pd.DataFrame()\n",
    "    for label in np.unique(y):\n",
    "        chi_sq, p = chi2(X_tfidf, y==label)\n",
    "        df_features = pd.concat([df_features,\n",
    "                                 pd.DataFrame({\n",
    "                                     \"feature\": X_names,\n",
    "                                     \"score\": 1-p,\n",
    "                                     \"y\": label\n",
    "                                 })])\n",
    "        df_features = df_features.sort_values(['y','score'],ascending=[True,False])\n",
    "        # keep those with high-enough p-value\n",
    "        df_features = df_features[df_features[\"score\"]>p_value_limit]\n",
    "    return df_features['feature'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "22204a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e06d62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Get the TF-IDF features that are most statistically \"relevant\"\n",
    "tfidf_vocab = chi2_tfidf(X_train['combined_clean'], y_train)\n",
    "# Initialize new TfidfVectorizer with the statistically \"relevant\" vocab\n",
    "tfidf = TfidfVectorizer(vocabulary=tfidf_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "543590cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('column_extractor', ColumnExtractor('combined_clean')),\n",
    "    ('tfidf', tfidf), # vectorize combined text\n",
    "    ('svc', svc),     # feed the output to classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "65ae398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6508620689655172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.69      0.69      0.69        98\n",
      "     fantasy       0.72      0.71      0.72       181\n",
      "     history       0.64      0.71      0.67       121\n",
      "      horror       0.65      0.56      0.60       115\n",
      "  psychology       0.65      0.59      0.62        22\n",
      "     romance       0.45      0.18      0.26        28\n",
      "     science       0.68      0.64      0.66       131\n",
      "      sports       0.65      0.79      0.71        14\n",
      "    thriller       0.60      0.66      0.63       206\n",
      "      travel       0.41      0.75      0.53        12\n",
      "\n",
      "    accuracy                           0.65       928\n",
      "   macro avg       0.61      0.63      0.61       928\n",
      "weighted avg       0.65      0.65      0.65       928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = pipeline.fit(X_train, y_train) # train the classifier\n",
    "y_pred = model.predict(X_test)          # apply model to test set\n",
    "\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print (f\"Accuracy: {score}\")\n",
    "print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "38b85dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def run_experiment(X, y, pipeline, num_expts=100):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "        X_names = chi2_tfidf(X_train['combined_clean'], y_train)\n",
    "        pipeline = Pipeline([\n",
    "            ('column_extractor', ColumnExtractor('combined_clean')),\n",
    "            ('tfidf', TfidfVectorizer(vocabulary=X_names)), # vectorize combined text\n",
    "            ('svc', svc),     # feed the output to classifier\n",
    "        ])\n",
    "        model = pipeline.fit(X_train, y_train) # train the classifier\n",
    "        y_pred = model.predict(X_test)         # apply model to test set\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(f\"Average accuracy over {num_expts} experiments: {sum(scores) / num_expts}\\n\")\n",
    "    print(\"Classification report for the last experiment:\\n\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99adbd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 5 experiments: 0.6549568965517242\n",
      "\n",
      "Classification report for the last experiment:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       crime       0.72      0.66      0.69       101\n",
      "     fantasy       0.71      0.74      0.73       172\n",
      "     history       0.65      0.73      0.69       121\n",
      "      horror       0.60      0.54      0.57       114\n",
      "  psychology       0.80      0.55      0.65        22\n",
      "     romance       0.46      0.22      0.30        27\n",
      "     science       0.70      0.73      0.71       131\n",
      "      sports       0.83      0.80      0.82        25\n",
      "    thriller       0.61      0.66      0.63       196\n",
      "      travel       0.67      0.63      0.65        19\n",
      "\n",
      "    accuracy                           0.67       928\n",
      "   macro avg       0.68      0.63      0.64       928\n",
      "weighted avg       0.67      0.67      0.66       928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(X, y, pipeline, num_expts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41118eb6",
   "metadata": {},
   "source": [
    "# Adding features to our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3e320d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apply(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, fn):\n",
    "        self.fn = np.vectorize(fn)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        trans_data = self.fn(data.reshape(data.size, 1))\n",
    "        return trans_data\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6c9dd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b8198d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def stopword_count(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]|_', '', text)\n",
    "    stopwords_in_text = [w for w in text.split() if w in stop_words]\n",
    "    return len(stopwords_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "94ba9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Get the TF-IDF features that are most statistically \"relevant\"\n",
    "tfidf_vocab = chi2_tfidf(X_train['combined_clean'], y_train)\n",
    "# Initialize new TfidfVectorizer with the statistically \"relevant\" vocab\n",
    "tfidf = TfidfVectorizer(vocabulary=tfidf_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "da74875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        print(X[0])\n",
    "        print('\\n')\n",
    "        print(X.shape)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4db0320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('combined', Pipeline([\n",
    "            ('combined_extractor', ColumnExtractor('combined_clean')),\n",
    "            ('tfidf', tfidf),\n",
    "            ('scale', StandardScaler(with_mean=False)),\n",
    "            #('scale', RobustScaler(with_centering=False)),\n",
    "            ('to_dense', DenseTransformer()),\n",
    "            ('pca', PCA(n_components=5)),\n",
    "            #('dim_reduction', TruncatedSVD())\n",
    "        ])),\n",
    "        ('title', Pipeline([\n",
    "            ('title_extractor', ColumnExtractor('title')), # extract titles\n",
    "            ('title_features', FeatureUnion([\n",
    "                ('title_char_count', Apply(lambda s: len(s))),\n",
    "        #        ('title_word_count', Apply(lambda s: len(s.split()))),\n",
    "        #        ('title_stopword_count', Apply(stopword_count))\n",
    "            ])),\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('to_dense', DenseTransformer()),\n",
    "    ('pca', PCA(n_components=4)),\n",
    "    ('svc', svc),     # feed the output to classifier\n",
    "    #('knn', knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "de02a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moonraker several minute stood speechless eye dazzled terrible beauty greatest weapon earth he selfmade millionaire head moonraker rocket programme loved press sir hugo drax cheating card bond five day uncover sinister truth behind national hero ian fleming third 007 adventure\n",
      "\n",
      "\n",
      "(3712,)\n",
      "  (0, 925)\t0.447650011213149\n",
      "  (0, 824)\t0.39605118532812117\n",
      "  (0, 798)\t0.4231812343788319\n",
      "  (0, 313)\t0.5204646549073653\n",
      "  (0, 248)\t0.439075291861001\n",
      "\n",
      "\n",
      "(3712, 1278)\n",
      "  (0, 925)\t12.771181990594897\n",
      "  (0, 824)\t7.4163609340742145\n",
      "  (0, 798)\t7.0918900380472705\n",
      "  (0, 313)\t11.069435850442442\n",
      "  (0, 248)\t7.9201235032557795\n",
      "\n",
      "\n",
      "(3712, 1278)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "\n",
      "(3712, 1278)\n",
      "[-0.11955408  0.66361594 -1.31009595 -0.76272009  0.10722529]\n",
      "\n",
      "\n",
      "(3712, 5)\n",
      "Moonraker\n",
      "\n",
      "\n",
      "(3712,)\n",
      "Moonraker\n",
      "\n",
      "\n",
      "(3712,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [251], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# train the classifier\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)          \u001b[38;5;66;03m# apply model to test set\u001b[39;00m\n\u001b[1;32m      4\u001b[0m score \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 378\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    334\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1154\u001b[0m, in \u001b[0;36mFeatureUnion.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit all transformers, transform the data and concatenate results.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03m        sum of `n_components` (output dimension) over transformers.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1176\u001b[0m, in \u001b[0;36mFeatureUnion._parallel_func\u001b[0;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformer_weights()\n\u001b[1;32m   1174\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter())\n\u001b[0;32m-> 1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatureUnion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:422\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    420\u001b[0m fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\u001b[38;5;241m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1162\u001b[0m, in \u001b[0;36mFeatureUnion.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m Xs, transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_transformer_list(transformers)\n\u001b[0;32m-> 1162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1218\u001b[0m, in \u001b[0;36mFeatureUnion._hstack\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mhstack(Xs)\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1218\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xs\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(X_train, y_train) # train the classifier\n",
    "y_pred = model.predict(X_test)          # apply model to test set\n",
    "\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print (f\"Accuracy: {score}\")\n",
    "print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab45c4",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e75b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
